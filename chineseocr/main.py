#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Sun Aug  4 01:01:37 2019
main 
@author: chineseocr
"""
from text.detector.detectors import TextDetector
from apphelper.image import rotate_cut_img,sort_box
import numpy as np
from PIL import Image
locations_ratio = [[0.38828125, 0.40703125, 0.03152173913043478, 0.051086956521739134], [0.303125, 0.31953125, 0.09891304347826087, 0.11847826086956521], 
            [0.38828125, 0.40703125, 0.07065217391304347, 0.09021739130434783], [0.32734375, 0.34296875, 0.11739130434782609, 0.13695652173913042], 
            [0.38828125, 0.40703125, 0.11195652173913044, 0.12934782608695652], [0.3484375, 0.36328125, 0.16847826086956522, 0.1858695652173913], 
            [0.38828125, 0.40703125, 0.16847826086956522, 0.1858695652173913], [0.47578125, 0.48984375, 0.09891304347826087, 0.11847826086956521], 
            [0.47578125, 0.48984375, 0.23478260869565218, 0.2532608695652174], [0.45078125, 0.465625, 0.11739130434782609, 0.13695652173913042], 
            [0.45078125, 0.465625, 0.21630434782608696, 0.23478260869565218], [0.43203125, 0.446875, 0.16847826086956522, 0.1858695652173913], 
            [0.303125, 0.31953125, 0.23478260869565218, 0.2532608695652174], [0.38828125, 0.40703125, 0.30434782608695654, 0.32282608695652176], 
            [0.32734375, 0.34296875, 0.21630434782608696, 0.23478260869565218], [0.38828125, 0.40703125, 0.26521739130434785, 0.2826086956521739], 
            [0.38828125, 0.40703125, 0.22608695652173913, 0.24347826086956523], [0.38828125, 0.40703125, 0.3652173913043478, 0.3815217391304348], 
            [0.303125, 0.31953125, 0.43369565217391304, 0.45], [0.38828125, 0.40703125, 0.4043478260869565, 0.4206521739130435], 
            [0.32734375, 0.34296875, 0.45217391304347826, 0.46956521739130436], [0.38828125, 0.40703125, 0.4434782608695652, 0.45869565217391306], 
            [0.3484375, 0.36328125, 0.5010869565217392, 0.5184782608695652], [0.38828125, 0.40703125, 0.5010869565217392, 0.5184782608695652], 
            [0.47578125, 0.48984375, 0.43369565217391304, 0.45], [0.47578125, 0.48984375, 0.5706521739130435, 0.5847826086956521], 
            [0.45078125, 0.465625, 0.45217391304347826, 0.46956521739130436], [0.45078125, 0.465625, 0.5489130434782609, 0.566304347826087], 
            [0.43203125, 0.446875, 0.5010869565217392, 0.5184782608695652], [0.303125, 0.31953125, 0.5489130434782609, 0.566304347826087], 
            [0.38828125, 0.40703125, 0.6369565217391304, 0.6543478260869565], [0.32734375, 0.34296875, 0.5489130434782609, 0.566304347826087], 
            [0.38828125, 0.40703125, 0.5956521739130435, 0.6152173913043478], [0.38828125, 0.40703125, 0.558695652173913, 0.5760869565217391]]
locations2_ratio = [[0.3939393939393939, 0.4117647058823529, 0.03184713375796178, 0.05222929936305733], [0.31283422459893045, 0.32798573975044565, 0.09936305732484077, 0.12101910828025478], 
                    [0.3939393939393939, 0.4117647058823529, 0.07133757961783439, 0.09171974522292993], [0.3360071301247772, 0.3538324420677362, 0.11847133757961784, 0.14012738853503184], 
                    [0.3939393939393939, 0.4117647058823529, 0.10828025477707007, 0.12993630573248408], [0.35472370766488415, 0.37254901960784315, 0.1681528662420382, 0.18980891719745224], 
                    [0.3939393939393939, 0.4117647058823529, 0.1681528662420382, 0.18980891719745224], [0.47771836007130125, 0.49554367201426025, 0.09936305732484077, 0.12101910828025478], 
                    [0.47771836007130125, 0.49554367201426025, 0.23439490445859873, 0.25605095541401274], [0.45454545454545453, 0.47237076648841353, 0.11847133757961784, 0.14012738853503184], 
                    [0.45454545454545453, 0.47237076648841353, 0.21528662420382166, 0.23694267515923567], [0.4358288770053476, 0.4536541889483066, 0.1681528662420382, 0.18980891719745224], 
                    [0.31283422459893045, 0.32798573975044565, 0.23439490445859873, 0.25605095541401274], [0.3939393939393939, 0.4117647058823529, 0.30318471337579617, 0.3248407643312102], 
                    [0.3360071301247772, 0.3538324420677362, 0.21528662420382166, 0.23694267515923567], [0.3939393939393939, 0.4117647058823529, 0.26369426751592356, 0.28535031847133757], 
                    [0.3939393939393939, 0.4117647058823529, 0.2267515923566879, 0.2484076433121019], [0.6158645276292335, 0.6336898395721925, 0.03184713375796178, 0.05222929936305733], 
                    [0.5329768270944741, 0.5508021390374331, 0.09936305732484077, 0.12101910828025478], [0.6158645276292335, 0.6336898395721925, 0.07133757961783439, 0.09171974522292993], 
                    [0.5570409982174688, 0.5748663101604278, 0.11847133757961784, 0.14012738853503184], [0.6158645276292335, 0.6336898395721925, 0.10828025477707007, 0.12993630573248408], 
                    [0.5748663101604278, 0.5926916221033868, 0.1681528662420382, 0.18980891719745224], [0.6158645276292335, 0.6336898395721925, 0.1681528662420382, 0.18980891719745224], 
                    [0.6987522281639929, 0.7165775401069518, 0.09936305732484077, 0.12101910828025478], [0.6987522281639929, 0.7165775401069518, 0.23439490445859873, 0.25605095541401274], 
                    [0.6755793226381461, 0.6934046345811051, 0.11847133757961784, 0.14012738853503184], [0.6755793226381461, 0.6934046345811051, 0.21528662420382166, 0.23694267515923567], 
                    [0.6577540106951871, 0.6755793226381461, 0.1681528662420382, 0.18980891719745224], [0.5329768270944741, 0.5508021390374331, 0.23439490445859873, 0.25605095541401274], 
                    [0.6158645276292335, 0.6336898395721925, 0.30318471337579617, 0.3248407643312102], [0.5570409982174688, 0.5748663101604278, 0.21528662420382166, 0.23694267515923567], 
                    [0.6158645276292335, 0.6336898395721925, 0.26369426751592356, 0.28535031847133757], [0.6158645276292335, 0.6336898395721925, 0.2267515923566879, 0.2484076433121019], 
                    [0.3939393939393939, 0.4117647058823529, 0.3668789808917197, 0.3885350318471338], [0.31283422459893045, 0.32798573975044565, 0.4318471337579618, 0.4535031847133758], 
                    [0.3939393939393939, 0.4117647058823529, 0.40254777070063696, 0.42420382165605097], [0.3360071301247772, 0.3538324420677362, 0.45095541401273886, 0.4726114649681529], 
                    [0.3939393939393939, 0.4117647058823529, 0.44331210191082804, 0.46496815286624205], [0.35472370766488415, 0.37254901960784315, 0.5019108280254777, 0.5235668789808917], 
                    [0.3939393939393939, 0.4117647058823529, 0.5019108280254777, 0.5235668789808917], [0.47771836007130125, 0.49554367201426025, 0.4318471337579618, 0.4535031847133758], 
                    [0.47771836007130125, 0.49554367201426025, 0.5681528662420382, 0.5898089171974522], [0.45454545454545453, 0.47237076648841353, 0.45095541401273886, 0.4726114649681529], 
                    [0.45454545454545453, 0.47237076648841353, 0.5490445859872611, 0.5707006369426751], [0.4358288770053476, 0.4536541889483066, 0.5019108280254777, 0.5235668789808917], 
                    [0.31283422459893045, 0.32798573975044565, 0.5681528662420382, 0.5898089171974522], [0.3939393939393939, 0.4117647058823529, 0.6369426751592356, 0.6585987261146496], 
                    [0.3360071301247772, 0.3538324420677362, 0.5490445859872611, 0.5707006369426751], [0.3939393939393939, 0.4117647058823529, 0.597452229299363, 0.619108280254777], 
                    [0.3939393939393939, 0.4117647058823529, 0.5592356687898089, 0.5808917197452229], [0.6158645276292335, 0.6336898395721925, 0.3668789808917197, 0.3885350318471338], 
                    [0.5329768270944741, 0.5508021390374331, 0.4318471337579618, 0.4535031847133758], [0.6158645276292335, 0.6336898395721925, 0.40254777070063696, 0.42420382165605097], 
                    [0.5570409982174688, 0.5748663101604278, 0.45095541401273886, 0.4726114649681529], [0.6158645276292335, 0.6336898395721925, 0.44331210191082804, 0.46496815286624205], 
                    [0.5748663101604278, 0.5926916221033868, 0.5019108280254777, 0.5235668789808917], [0.6158645276292335, 0.6336898395721925, 0.5019108280254777, 0.5235668789808917], 
                    [0.6987522281639929, 0.7165775401069518, 0.4318471337579618, 0.4535031847133758], [0.6987522281639929, 0.7165775401069518, 0.5681528662420382, 0.5898089171974522], 
                    [0.6755793226381461, 0.6934046345811051, 0.45095541401273886, 0.4726114649681529], [0.6755793226381461, 0.6934046345811051, 0.5490445859872611, 0.5707006369426751], 
                    [0.6577540106951871, 0.6755793226381461, 0.5019108280254777, 0.5235668789808917], [0.5329768270944741, 0.5508021390374331, 0.5681528662420382, 0.5898089171974522], 
                    [0.6158645276292335, 0.6336898395721925, 0.6369426751592356, 0.6585987261146496], [0.5570409982174688, 0.5748663101604278, 0.5490445859872611, 0.5707006369426751], 
                    [0.6158645276292335, 0.6336898395721925, 0.597452229299363, 0.619108280254777], [0.6158645276292335, 0.6336898395721925, 0.559235668789808, 0.580891719745222]] 
class TextOcrModel(object):
    def __init__(self,ocrModel,textModel,angleModel):
        self.ocrModel = ocrModel
        self.textModel = textModel
        self.angleModel = angleModel
    
    def detect_angle(self,img):
        """
        detect text angle in [0,90,180,270]
        @@img:np.array
        """
        angle = self.angleModel(img)
        if angle==90:
            im = Image.fromarray(img).transpose(Image.ROTATE_90)
            img = np.array(im)
        elif angle==180:
            im = Image.fromarray(img).transpose(Image.ROTATE_180)
            img = np.array(im)
        elif angle==270:
            im = Image.fromarray(img).transpose(Image.ROTATE_270)
            img = np.array(im)
        
        return img,angle
    
    def detect_box(self,img,scale=600,maxScale=900):
        """
        detect text angle in [0,90,180,270]
        @@img:np.array
        """
        boxes,scores = self.textModel(img,scale,maxScale)
        return boxes,scores
    
    def box_cluster(self,img,boxes,scores,**args):
        
        MAX_HORIZONTAL_GAP= args.get('MAX_HORIZONTAL_GAP',100)
        MIN_V_OVERLAPS    = args.get('MIN_V_OVERLAPS',0.6)
        MIN_SIZE_SIM      = args.get('MIN_SIZE_SIM',0.6)
        textdetector = TextDetector(MAX_HORIZONTAL_GAP,MIN_V_OVERLAPS,MIN_SIZE_SIM)
        
        shape = img.shape[:2]
        TEXT_PROPOSALS_MIN_SCORE     = args.get('TEXT_PROPOSALS_MIN_SCORE',0.7)
        TEXT_PROPOSALS_NMS_THRESH    = args.get('TEXT_PROPOSALS_NMS_THRESH',0.3)
        TEXT_LINE_NMS_THRESH         = args.get('TEXT_LINE_NMS_THRESH',0.3)
        LINE_MIN_SCORE               = args.get('LINE_MIN_SCORE',0.8)
        
        boxes,scores = textdetector.detect(boxes,
                                scores[:, np.newaxis],
                                shape,
                                TEXT_PROPOSALS_MIN_SCORE,
                                TEXT_PROPOSALS_NMS_THRESH,
                                TEXT_LINE_NMS_THRESH,
                                LINE_MIN_SCORE
                                )
        return boxes,scores
    
    
    def ocr_batch(self,img,boxes,leftAdjustAlph=0.0,rightAdjustAlph=0.0, category = 0):
        """
        batch for ocr
        """
        im = Image.fromarray(img)
        newBoxes = []
        for index,box in enumerate(boxes):
            partImg,box = rotate_cut_img(im,box,leftAdjustAlph,rightAdjustAlph)
            box['img'] = partImg.convert('L')
            newBoxes.append(box)
        if category == 0:
            for location_ratio in locations_ratio:
                box = {'cx':(location_ratio[0] + location_ratio[1]) * im.size[0] / 2,'cy':(location_ratio[2] + location_ratio[3]) * im.size[1] / 2,'w':(location_ratio[1] - location_ratio[0]) * im.size[0],'h':(location_ratio[3] - location_ratio[2]) * im.size[1],'degree':0,}
                box['img'] = im.crop((int(location_ratio[0] * im.size[0]), int(location_ratio[2] * im.size[1]), int(location_ratio[1] * im.size[0]), int(location_ratio[3] * im.size[1]))).convert('L')
                newBoxes.append(box)
        elif category == 1:
            for location2_ratio in locations2_ratio:
                box = {'cx':(location2_ratio[0] + location2_ratio[1]) * im.size[0] / 2,'cy':(location2_ratio[2] + location2_ratio[3]) * im.size[1] / 2,'w':(location2_ratio[1] - location2_ratio[0]) * im.size[0],'h':(location2_ratio[3] - location2_ratio[2]) * im.size[1],'degree':0,}
                box['img'] = im.crop((int(location2_ratio[0] * im.size[0]), int(location2_ratio[2] * im.size[1]), int(location2_ratio[1] * im.size[0]), int(location2_ratio[3] * im.size[1]))).convert('L')
                newBoxes.append(box)
        res = self.ocrModel(newBoxes)
        return res
    
    
    def model(self,img,category, **args):
        detectAngle        = args.get('detectAngle',False)
        if detectAngle:
            img,angle      = self.detect_angle(img)
        else:
            angle          = 0
        scale              = args.get('scale',608)
        maxScale           = args.get('maxScale',608)
        boxes,scores       = self.detect_box(img,scale,maxScale)##文字检测
        boxes,scores       = self.box_cluster(img,boxes,scores,**args)
        boxes              = sort_box(boxes)
        leftAdjustAlph     = args.get('leftAdjustAlph',0)
        rightAdjustAlph    = args.get('rightAdjustAlph',0)
        res                = self.ocr_batch(img,boxes,leftAdjustAlph,rightAdjustAlph,category)
        return res,angle
        
    
